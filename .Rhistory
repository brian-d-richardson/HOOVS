# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
rm(list = ls())
library(MASS)
library(ordinalNet)
library(foreign)
library(ggplot2)
library(devtools)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# example of ordinal regression with LASSO using ordinalNet::ordinalNet()
ord.mod.net <- ordinalNet::ordinalNet(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
alpha = 1, # alpha = 1 corresponds to LASSO
family = "cumulative",
link = "logit",
lambdaVals = c(0, 1/n)
)
ord.mod.net$coefs
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 1)
ord.mod.lambda1
# the MASS::polr() function does a better job of maximizing the likelihood
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.lambda0$alpha))),
beta = ord.mod.lambda0$beta)
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.polr$zeta))),
beta = -ord.mod.polr$coefficients)
# the MASS::polr() function does a better job of maximizing the likelihood
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.lambda0$alpha))),
beta = ord.mod.lambda0$beta)
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.polr$zeta))),
beta = -ord.mod.polr$coefficients)
param.est <- data.frame("Method" = rep(c("MASS:polr()",
"ordreg.lasso() with Lambda = 0",
"ordreg.lasso() with Lambda = 1"),
each = p + J - 1),
"Parameter" = rep(c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
times = 3),
"Truth" = rep(c(alpha0, beta0), times = 3),
"Estimate" = c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients,
ord.mod.lambda0$alpha, ord.mod.lambda0$beta,
ord.mod.lambda1$alpha, ord.mod.lambda1$beta))
ggplot(param.est,
aes(x = Method,
y = Estimate,
color = Method,
shape = Method)) +
geom_point(size = 2) +
geom_hline(aes(yintercept = Truth),
linetype = "dashed") +
facet_wrap(~ Parameter) +
labs(x = "") +
ggtitle("Parameter Estimates for Different Model Fitting Methods") +
theme_bw() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#'
#' @return a list with the following elements:
#' \itemize{
#' \item{alpha: the estimated category specific intercepts for the lowest J-1 outcome categories; a numeric vector of length J-1}
#' \item{beta: the estimated slopes; a numeric vector of length p}
#' \item{loglik: the log-likelihood value at convergence (not including the LASSO penalty)}
#' \item{lasso.penalty: the penalty term evaluated at the estimates for alpha and beta}
#' }
#'
#' @export
ordreg.lasso <- function(formula, data, lambda = 0) {
# extract outcome vector from data
y <- data[, all.vars(formula)[1]]
# number of categories minus 1
J_1 <- nlevels(y) - 1
# extract covariate matrix (not including intercept)
x <- model.matrix(formula, data)[, -1]
# maximize likelihood
opt.res <- optim(par = c(seq(0, 1, length = J_1),
rep(0, ncol(x))),
fn = function(theta) {
beta <- theta[-(1:J_1)]
zeta <- theta[1:J_1]
-(1 / length(y)) * (
# log-likelihood
loglik(zeta = zeta,
beta = beta,
y = y,
x = x)) +
# LASSO penalty
lambda * sum(abs(beta))
},
method = "BFGS")
#method = "Nelder-Mead")
# estimated alpha and beta
alpha <- cumsum(exp(opt.res$par[1:J_1]))
beta <- opt.res$par[-(1:J_1)]
# LASSO penalty term
lasso.penalty <- lambda * sum(abs(beta))
# log-likelihood value at convergence (not including LASSO penalty)
ll <- -1 * length(y) * opt.res$value + lasso.penalty
return(list("alpha" = alpha,
"beta" = beta,
"loglik" = ll,
"lasso.penalty" = lasso.penalty))
}
rm(list = ls())
library(MASS)
library(ordinalNet)
library(foreign)
library(ggplot2)
library(devtools)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# example of ordinal regression with LASSO using ordinalNet::ordinalNet()
ord.mod.net <- ordinalNet::ordinalNet(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
alpha = 1, # alpha = 1 corresponds to LASSO
family = "cumulative",
link = "logit",
lambdaVals = c(0, 1/n)
)
ord.mod.net$coefs
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 1)
ord.mod.lambda1
# the MASS::polr() function does a better job of maximizing the likelihood
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.lambda0$alpha))),
beta = ord.mod.lambda0$beta)
loglik(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
zeta = log(diff(c(0, ord.mod.polr$zeta))),
beta = -ord.mod.polr$coefficients)
param.est <- data.frame("Method" = rep(c("MASS:polr()",
"ordreg.lasso() with Lambda = 0",
"ordreg.lasso() with Lambda = 1"),
each = p + J - 1),
"Parameter" = rep(c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
times = 3),
"Truth" = rep(c(alpha0, beta0), times = 3),
"Estimate" = c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients,
ord.mod.lambda0$alpha, ord.mod.lambda0$beta,
ord.mod.lambda1$alpha, ord.mod.lambda1$beta))
View(param.est)
ggplot(param.est,
aes(x = Method,
y = Estimate,
color = Method,
shape = Method)) +
geom_point(size = 2) +
geom_hline(aes(yintercept = Truth),
linetype = "dashed") +
facet_wrap(~ Parameter) +
labs(x = "") +
ggtitle("Parameter Estimates for Different Model Fitting Methods") +
theme_bw() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.1)
ord.mod.lambda1
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients),
"ordreg.lasso.0" = ord.mod.lambda0$alpha, ord.mod.lambda0$beta,
"ordreg.lasso.1" = ord.mod.lambda1$alpha, ord.mod.lambda1$beta)
c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p))
c(alpha0, beta0)
c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients),
"ordreg.lasso.0" = c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta),
"ordreg.lasso.1" = c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta))
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3))
library(kableExtra)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable_classic()
rm(list = ls())
library(MASS)
library(ordinalNet)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# example of ordinal regression with LASSO using ordinalNet::ordinalNet()
ord.mod.net <- ordinalNet::ordinalNet(x = as.matrix(dat[, paste0("X", 1:p)]),
y = dat$y,
alpha = 1, # alpha = 1 corresponds to LASSO
family = "cumulative",
link = "logit",
lambdaVals = c(0, 1/n)
)
ord.mod.net$coefs
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.1)
ord.mod.lambda1
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable_classic()
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3))
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(_classic()))
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable()
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.01)
ord.mod.lambda1
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.05)
ord.mod.lambda1
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.01)"))
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3),
row.names = F) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
row.names = ""
caption = "Ordinal Regression Model Estimates by Method") %>%
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3),
row.names = F) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)")) %>%
caption = "Ordinal Regression Model Estimates by Method") %>%
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3),
row.names = F) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3),
row.names = F) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
row.names = NULL,
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
row.names = NULL,
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3))
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
row.names = NULL,
caption = "Ordinal Regression Model Estimates by Method")
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambd = 0)",
"ordreg.lasso (lambd = 0.05)"),
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
