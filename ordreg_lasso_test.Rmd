---
title: "Test of Ordinal Regression with LASSO"
author: "Brian Richardson"
output: html_document
---

```{r setup, include=FALSE}

rm(list = ls())

library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
load_all()

set.seed(1)

```

The goal of this program is to compare our ordinal regression function code with an existing function, and to verify that the lasso component of our function works as expected.

We begin by simulating a data set.

```{r}

# sample size
n <- 1000

# number of covariates
p <- 10

# number of categories for ordinal outcome
J <- 4

# create n x p covariate matrix
X <- matrix(nrow = n,
            ncol = p,
            data = rnorm(n*p))

# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
           rep(0, p - 4)) 

# linear predictors
eta0 <- X %*% beta0

# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
                    ncol = J)
for (j in 1:(J-1)) {
  cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1

# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])

# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
  y[i] <- sample(x = 1:J,
                 size = 1,
                 prob = probs[i,])
}

# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)

```

We then use an existing function `MASS::polr()` to run an ordinal logistic regression model on the simulated data set.

```{r}

# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)

```

We can now test our own version of an ordinal regression function.

```{r}

# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
                                data = dat,
                                lambda = 0)
ord.mod.lambda0

# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
                                data = dat,
                                lambda = 1)
ord.mod.lambda1

```

We can now compare the parameter estimates between the 3 methods for fitting the model.

```{r fig.width = 10, fig.height = 6}

param.est <- data.frame("Method" = rep(c("MASS:polr()",
                                         "ordreg.lasso() with Lambda = 0",
                                         "ordreg.lasso() with Lambda = 1"),
                                       each = p + J - 1),
                        "Parameter" = rep(c(paste0("alpha", 1:(J-1)),
                                            paste0("beta", 1:p)),
                                          times = 3),
                        "Truth" = rep(c(alpha0, beta0), times = 3),
                        "Estimate" = c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients,
                                       ord.mod.lambda0$alpha, ord.mod.lambda0$beta,
                                       ord.mod.lambda1$alpha, ord.mod.lambda1$beta))

ggplot(param.est,
       aes(x = Method,
           y = Estimate,
           color = Method,
           shape = Method)) +
  geom_point(size = 2) +
  geom_hline(aes(yintercept = Truth),
             linetype = "dashed") +
  facet_wrap(~ Parameter) +
  labs(x = "") +
  ggtitle("Parameter Estimates for Different Model Fitting Methods") +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

```










