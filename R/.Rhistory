library(devtools)
seq(0, 1, 2)
seq(0, 1, 4)
seq(0, 1, length = 4)
document()
rlang::last_error()
document()
document()
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.05)
ord.mod.lambda1
sqrt(diag(ord.mod.lambda0$vcov))
diag(ord.mod.lambda0$vcov)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# linear predictors
eta0 <- X %*% beta0
# compute the cumulative probabilities for each of J categories and n subjects
cum.probs <- matrix(nrow = n,
ncol = J)
for (j in 1:(J-1)) {
cum.probs[, j] <- inv.logit(alpha0[j] + eta0)
}
cum.probs[, J] <- 1
# compute the probabilities for each of J categories and n subjects
probs <- cum.probs - cbind(0, cum.probs[, -J])
# simulate outcomes
y <- numeric(n)
for (i in 1:n) {
y[i] <- sample(x = 1:J,
size = 1,
prob = probs[i,])
}
# combine into one data set
dat <- data.frame(cbind(y, X))
colnames(dat) <- c("y", paste0("X", 1:p))
dat$y <- factor(dat$y, levels = 1:J, ordered = T)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.05)
ord.mod.lambda1
sqrt(diag(ord.mod.lambda0$vcov))
document()
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
dat <- sim.data(formula = y ~ ., n = 1000, alpha = alpha0, beta = beta0)
View(dat)
# example of ordinal regression using existing function MASS::polr
ord.mod.polr <- polr(polr(y ~ ., data = dat))
summary(ord.mod.polr)
logLik(ord.mod.polr)
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
# test our ordinal regression function with a LASSO penalty
ord.mod.lambda1 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0.05)
ord.mod.lambda1
data.frame("Parameter" = c(paste0("alpha", 1:(J-1)),
paste0("beta", 1:p)),
"Truth" = c(alpha0, beta0),
"polr" = round(c(ord.mod.polr$zeta, -1 * ord.mod.polr$coefficients), 3),
"ordreg.lasso.0" = round(c(ord.mod.lambda0$alpha, ord.mod.lambda0$beta), 3),
"ordreg.lasso.1" = round(c(ord.mod.lambda1$alpha, ord.mod.lambda1$beta), 3)) %>%
kable(col.names = c("Paremeter", "Truth", "MASS:polr()",
"ordreg.lasso (lambda = 0)",
"ordreg.lasso (lambda = 0.05)"),
caption = "Ordinal Regression Model Estimates by Method") %>%
kable_classic(full_width = F)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
rm(list = ls())
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# simulate data according to the above parameters
dat <- sim.data(formula = y ~ .,
n = 1000,
alpha = alpha0,
beta = beta0)
alpha0
beta0
dat[1:10, ]
dat[1:10, ] %>%
mutate_all(round(digits = 2))
library(dplyr)
dat[1:10, ] %>%
mutate_all(round(digits = 2))
round(dat[1:10, ], 3)
dat[1:10, ] %>%
mutate_all(.funs = round(digits = 2))
dat[1:10, ] %>%
mutate_all(.funs = function(x) round(x, digits = 2))
dat[1:10, ] %>%
mutate_if(is.numeric(),
.funs = function(x) round(x, digits = 2))
dat[1:10, ] %>%
mutate_if(is.numeric(x),
.funs = function(x) round(x, digits = 2))
dat[1:10, ] %>%
mutate_if(.predicate = function(x) is.numeric(x),
.funs = function(x) round(x, digits = 2))
rm(list = ls())
library(dplyr)
library(MASS)
library(foreign)
library(ggplot2)
library(devtools)
library(kableExtra)
load_all()
set.seed(1)
# sample size
n <- 1000
# number of covariates
p <- 10
# number of categories for ordinal outcome
J <- 4
# create n x p covariate matrix
X <- matrix(nrow = n,
ncol = p,
data = rnorm(n*p))
# set population parameters
alpha0 <- seq(.5, 1.5, length = J - 1) # category-specific intercepts
beta0 <- c(rep(1, 4), # slopes
rep(0, p - 4))
# simulate data according to the above parameters
dat <- sim.data(formula = y ~ .,
n = 1000,
alpha = alpha0,
beta = beta0)
dat[1:10, ] %>%
mutate_if(.predicate = function(x) is.numeric(x),
.funs = function(x) round(x, digits = 2))
# test our ordinal regression function with no LASSO penalty
ord.mod.lambda0 <- ordreg.lasso(formula = y ~ .,
data = dat,
lambda = 0)
ord.mod.lambda0
